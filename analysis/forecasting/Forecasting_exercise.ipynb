{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ba9479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data_daily = pd.read_csv('data_for_forecasting.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88d3279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_ret</th>\n",
       "      <th>equally_weighted_index</th>\n",
       "      <th>equally_weighted_volume</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment_LM</th>\n",
       "      <th>sentiment_extend</th>\n",
       "      <th>Component1extend</th>\n",
       "      <th>Component2extend</th>\n",
       "      <th>Component3extend</th>\n",
       "      <th>Component4extend</th>\n",
       "      <th>...</th>\n",
       "      <th>Component1LM</th>\n",
       "      <th>Component2LM</th>\n",
       "      <th>Component3LM</th>\n",
       "      <th>Component4LM</th>\n",
       "      <th>Component5LM</th>\n",
       "      <th>Component6LM</th>\n",
       "      <th>Component7LM</th>\n",
       "      <th>Component8LM</th>\n",
       "      <th>Component9LM</th>\n",
       "      <th>Component10LM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024653</td>\n",
       "      <td>123.982993</td>\n",
       "      <td>955224.563689</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.915952</td>\n",
       "      <td>0.198014</td>\n",
       "      <td>0.148710</td>\n",
       "      <td>0.144552</td>\n",
       "      <td>...</td>\n",
       "      <td>1.669572</td>\n",
       "      <td>-0.104760</td>\n",
       "      <td>-0.040353</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>0.455844</td>\n",
       "      <td>0.089934</td>\n",
       "      <td>0.093672</td>\n",
       "      <td>-0.672846</td>\n",
       "      <td>-0.219977</td>\n",
       "      <td>0.186504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.032606</td>\n",
       "      <td>120.005545</td>\n",
       "      <td>850090.878743</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.915952</td>\n",
       "      <td>0.198014</td>\n",
       "      <td>0.148710</td>\n",
       "      <td>0.144552</td>\n",
       "      <td>...</td>\n",
       "      <td>1.669572</td>\n",
       "      <td>-0.104760</td>\n",
       "      <td>-0.040353</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>0.455844</td>\n",
       "      <td>0.089934</td>\n",
       "      <td>0.093672</td>\n",
       "      <td>-0.672846</td>\n",
       "      <td>-0.219977</td>\n",
       "      <td>0.186504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004484</td>\n",
       "      <td>120.544918</td>\n",
       "      <td>759009.187526</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.915952</td>\n",
       "      <td>0.198014</td>\n",
       "      <td>0.148710</td>\n",
       "      <td>0.144552</td>\n",
       "      <td>...</td>\n",
       "      <td>1.669572</td>\n",
       "      <td>-0.104760</td>\n",
       "      <td>-0.040353</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>0.455844</td>\n",
       "      <td>0.089934</td>\n",
       "      <td>0.093672</td>\n",
       "      <td>-0.672846</td>\n",
       "      <td>-0.219977</td>\n",
       "      <td>0.186504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.028255</td>\n",
       "      <td>117.186612</td>\n",
       "      <td>438230.369985</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>3.278263</td>\n",
       "      <td>-0.527159</td>\n",
       "      <td>-0.984497</td>\n",
       "      <td>1.777233</td>\n",
       "      <td>...</td>\n",
       "      <td>4.347198</td>\n",
       "      <td>-0.908943</td>\n",
       "      <td>2.394316</td>\n",
       "      <td>-0.003131</td>\n",
       "      <td>0.014896</td>\n",
       "      <td>-1.534704</td>\n",
       "      <td>1.364388</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.972589</td>\n",
       "      <td>-0.302632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047632</td>\n",
       "      <td>122.903516</td>\n",
       "      <td>597259.923840</td>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.768733</td>\n",
       "      <td>0.020885</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>0.303239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573484</td>\n",
       "      <td>-0.299402</td>\n",
       "      <td>-1.087171</td>\n",
       "      <td>0.172037</td>\n",
       "      <td>0.295554</td>\n",
       "      <td>0.732241</td>\n",
       "      <td>-0.741438</td>\n",
       "      <td>-0.244923</td>\n",
       "      <td>-0.427908</td>\n",
       "      <td>-0.176453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    log_ret  equally_weighted_index  equally_weighted_volume        date  \\\n",
       "0  0.024653              123.982993            955224.563689  2016-01-13   \n",
       "1 -0.032606              120.005545            850090.878743  2016-01-14   \n",
       "2  0.004484              120.544918            759009.187526  2016-01-15   \n",
       "3 -0.028255              117.186612            438230.369985  2016-01-18   \n",
       "4  0.047632              122.903516            597259.923840  2016-01-19   \n",
       "\n",
       "   sentiment_LM  sentiment_extend  Component1extend  Component2extend  \\\n",
       "0      0.003378          0.002483          0.915952          0.198014   \n",
       "1      0.003378          0.002483          0.915952          0.198014   \n",
       "2      0.003378          0.002483          0.915952          0.198014   \n",
       "3      0.006187          0.006968          3.278263         -0.527159   \n",
       "4     -0.002157          0.000638          0.768733          0.020885   \n",
       "\n",
       "   Component3extend  Component4extend  ...  Component1LM  Component2LM  \\\n",
       "0          0.148710          0.144552  ...      1.669572     -0.104760   \n",
       "1          0.148710          0.144552  ...      1.669572     -0.104760   \n",
       "2          0.148710          0.144552  ...      1.669572     -0.104760   \n",
       "3         -0.984497          1.777233  ...      4.347198     -0.908943   \n",
       "4          0.008943          0.303239  ...     -0.573484     -0.299402   \n",
       "\n",
       "   Component3LM  Component4LM  Component5LM  Component6LM  Component7LM  \\\n",
       "0     -0.040353      0.042248      0.455844      0.089934      0.093672   \n",
       "1     -0.040353      0.042248      0.455844      0.089934      0.093672   \n",
       "2     -0.040353      0.042248      0.455844      0.089934      0.093672   \n",
       "3      2.394316     -0.003131      0.014896     -1.534704      1.364388   \n",
       "4     -1.087171      0.172037      0.295554      0.732241     -0.741438   \n",
       "\n",
       "   Component8LM  Component9LM  Component10LM  \n",
       "0     -0.672846     -0.219977       0.186504  \n",
       "1     -0.672846     -0.219977       0.186504  \n",
       "2     -0.672846     -0.219977       0.186504  \n",
       "3      0.121622      0.972589      -0.302632  \n",
       "4     -0.244923     -0.427908      -0.176453  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25436f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classify_return(row, lower, upper):\n",
    "    if row < lower:\n",
    "        return 0\n",
    "    elif lower <= row <= upper:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def label_returns(df):\n",
    "    lower_quantile = df['log_ret'].quantile(0.25)\n",
    "    upper_quantile = df['log_ret'].quantile(0.75)\n",
    "\n",
    "    df['labels'] = df['log_ret'].apply(classify_return, args=(lower_quantile, upper_quantile))\n",
    "    return df\n",
    "\n",
    "data_daily = label_returns(data_daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1febae0d",
   "metadata": {},
   "source": [
    "## Prices only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e85503",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_daily['labels'][1:]\n",
    "columns = ['equally_weighted_index', 'equally_weighted_volume']\n",
    "X = data_daily[columns].iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f407b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Determine the split point for 90% of the data\n",
    "split_point = int(len(X) * 0.90)\n",
    "\n",
    "# Split the data without shuffling\n",
    "X_train, X_test = X[:split_point], X[split_point:]\n",
    "y_train, y_test = y[:split_point], y[split_point:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bac8a10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 5.623413251903491, 'degree': 3}\n",
      "CPU times: total: 1h 50min 1s\n",
      "Wall time: 1h 50min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter ranges\n",
    "C_range = [10**i for i in np.arange(0, 3.25, 0.25)]\n",
    "degree_range = [2, 3, 4, 5]\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'C': C_range, 'degree': degree_range}\n",
    "\n",
    "# Create the SVC model with a polynomial kernel\n",
    "svc = SVC(kernel='poly', class_weight='balanced')\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=10, scoring='f1_weighted')\n",
    "\n",
    "# Fit the GridSearchCV model\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters: ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a4186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = grid_search.best_params_['C']\n",
    "best_d = grid_search.best_params_['degree']\n",
    "\n",
    "# Create a SVC model with the best parameters\n",
    "svc_model_best = SVC(C=best_c, kernel='poly', degree=best_d, decision_function_shape='ovo')\n",
    "\n",
    "# Train the model\n",
    "svc_model_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compute predicted labels for the test set\n",
    "predictions = svc_model_best.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f73b1bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.45      1.00      0.62        74\n",
      "           2       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.45       163\n",
      "   macro avg       0.15      0.33      0.21       163\n",
      "weighted avg       0.21      0.45      0.28       163\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0]\n",
      " [40 74 49]\n",
      " [ 0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "# Print out classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions, zero_division=0))\n",
    "\n",
    "# Compute and print out confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdb3512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.4539877300613497\n",
      "Weighted Macro F1-Score: 0.28350288628303694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Calculate average accuracy\n",
    "accuracy_p = accuracy_score(y_test, predictions)\n",
    "print(f\"Average Accuracy: {accuracy_p}\")\n",
    "\n",
    "# Get classification report as a dictionary\n",
    "classification_report_dict = classification_report(y_test, predictions, zero_division=0, output_dict=True)\n",
    "\n",
    "# Extract weighted macro F1-score\n",
    "f1_p = classification_report_dict['weighted avg']['f1-score']\n",
    "print(f\"Weighted Macro F1-Score: {f1_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc563b4",
   "metadata": {},
   "source": [
    "## Prices and sentiment LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d343506",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_daily['labels'][1:]\n",
    "columns = ['equally_weighted_index', 'equally_weighted_volume', 'sentiment_LM']\n",
    "X = data_daily[columns].iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "124f1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the split point for 90% of the data\n",
    "split_point = int(len(X) * 0.90)\n",
    "\n",
    "# Split the data without shuffling\n",
    "X_train, X_test = X[:split_point], X[split_point:]\n",
    "y_train, y_test = y[:split_point], y[split_point:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bd994e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 3.1622776601683795, 'degree': 2}\n",
      "CPU times: total: 1h 37min 55s\n",
      "Wall time: 1h 38min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter ranges\n",
    "C_range = [10**i for i in np.arange(0, 3.25, 0.25)]\n",
    "degree_range = [2, 3, 4, 5]\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'C': C_range, 'degree': degree_range}\n",
    "\n",
    "# Create the SVC model with a polynomial kernel\n",
    "svc = SVC(kernel='poly', class_weight='balanced')\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=10, scoring='f1_weighted')\n",
    "\n",
    "# Fit the GridSearchCV model\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters: ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60e10d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = grid_search.best_params_['C']\n",
    "best_d = grid_search.best_params_['degree']\n",
    "\n",
    "# Create a SVC model with the best parameters\n",
    "svc_model_best = SVC(C=best_c, kernel='poly', degree=best_d, decision_function_shape='ovo')\n",
    "\n",
    "# Train the model\n",
    "svc_model_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compute predicted labels for the test set\n",
    "predictions = svc_model_best.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63389615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.45      1.00      0.62        74\n",
      "           2       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.45       163\n",
      "   macro avg       0.15      0.33      0.21       163\n",
      "weighted avg       0.21      0.45      0.28       163\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0]\n",
      " [40 74 49]\n",
      " [ 0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "# Print out classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions, zero_division=0))\n",
    "\n",
    "# Compute and print out confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d235e612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.4539877300613497\n",
      "Weighted Macro F1-Score: 0.28350288628303694\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracy_p_lm = accuracy_score(y_test, predictions)\n",
    "print(f\"Average Accuracy: {accuracy_p_lm}\")\n",
    "\n",
    "# Get classification report as a dictionary\n",
    "classification_report_dict = classification_report(y_test, predictions, zero_division=0, output_dict=True)\n",
    "\n",
    "# Extract weighted macro F1-score\n",
    "f1_p_lm = classification_report_dict['weighted avg']['f1-score']\n",
    "print(f\"Weighted Macro F1-Score: {f1_p_lm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c0e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative improvement for accuracy: 0.0\n",
      "Relative improvement for F1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "delta_lm = (accuracy_p_lm - accuracy_p) / accuracy_p\n",
    "delta_lm_f1 = (f1_p_lm - f1_p) / f1_p\n",
    "\n",
    "print(f\"Relative improvement for accuracy: {delta_lm}\")\n",
    "print(f\"Relative improvement for F1 score: {delta_lm_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57721be",
   "metadata": {},
   "source": [
    "## Prices and components based on topics*LM sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4df7a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lags(df, column_name, max_lag):\n",
    "    \"\"\"\n",
    "    This function adds lagged values of a specified column to a copy of the dataframe.\n",
    "    \n",
    "    Args:\n",
    "    df: The dataframe.\n",
    "    column_name: The name of the column for which lagged values are to be added.\n",
    "    max_lag: The maximum number of lags to be added.\n",
    "    \n",
    "    Returns:\n",
    "    df_copy: A copy of the dataframe with added lagged value columns.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()  # Create a copy of the DataFrame\n",
    "    for lag in range(1, max_lag + 1):\n",
    "        df_copy[f'{column_name}_lag_{lag}'] = df_copy[column_name].shift(lag)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "030d6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test first\n",
    "mask = (data_daily['date'] <= '2021-11-12')\n",
    "train_data = data_daily.loc[mask]\n",
    "mask = (data_daily['date'] >= '2021-11-12')\n",
    "test_data = data_daily.loc[mask]\n",
    "\n",
    "# Add lags to 'equally_weighted_index', 'equally_weighted_volume' and 'ComponentiLM' columns in train set\n",
    "train_data = add_lags(train_data, 'equally_weighted_index', 1)\n",
    "train_data = add_lags(train_data, 'equally_weighted_volume', 1)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    train_data = add_lags(train_data, f'Component{i}LM', 10)\n",
    "\n",
    "# Select the required columns\n",
    "required_columns = ['equally_weighted_index_lag_1', 'equally_weighted_volume_lag_1'] + [f'Component{i}LM_lag_{j}' for i in range(1, 11) for j in range(1, 11)]\n",
    "X = train_data[required_columns]\n",
    "y = train_data['labels'].shift(-10)\n",
    "X_train = X.dropna().reset_index(drop=True)\n",
    "y_train = y.dropna().reset_index(drop=True).iloc[:len(X_train)]\n",
    "\n",
    "# Add lags to 'equally_weighted_index', 'equally_weighted_volume' and 'ComponentiLM' columns in test set\n",
    "test_data = add_lags(test_data, 'equally_weighted_index', 1)\n",
    "test_data = add_lags(test_data, 'equally_weighted_volume', 1)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    test_data = add_lags(test_data, f'Component{i}LM', 10)\n",
    "\n",
    "# Select the required columns\n",
    "required_columns = ['equally_weighted_index_lag_1', 'equally_weighted_volume_lag_1'] + [f'Component{i}LM_lag_{j}' for i in range(1, 11) for j in range(1, 11)]\n",
    "X = test_data[required_columns]\n",
    "y = test_data['labels'].shift(-10)\n",
    "X_test = X.dropna().reset_index(drop=True)\n",
    "y_test = y.dropna().reset_index(drop=True).iloc[:len(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba86f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component10LM_lag_7: 0.051230184241513294\n",
      "Component8LM_lag_6: 0.04940627003969241\n",
      "Component6LM_lag_9: 0.04731174252128467\n",
      "Component2LM_lag_5: 0.0466248893319868\n",
      "Component6LM_lag_8: 0.038765315105760235\n"
     ]
    }
   ],
   "source": [
    "# Drop the specified columns\n",
    "X_train_dropped = X_train.drop(['equally_weighted_index_lag_1', 'equally_weighted_volume_lag_1'], axis=1)\n",
    "\n",
    "# Calculate correlations of all remaining variables with `train_data['log_ret'].iloc[10:]`\n",
    "correlations = X_train_dropped.corrwith(train_data['log_ret'].iloc[10:])\n",
    "\n",
    "# Sort correlations in descending order\n",
    "sorted_correlations = correlations.sort_values(ascending=False)\n",
    "\n",
    "# Select top 5\n",
    "top_5_variables = sorted_correlations[:5]\n",
    "\n",
    "# Print top 5 variables along with their correlation coefficients\n",
    "for variable, correlation in top_5_variables.items():\n",
    "    print(f\"{variable}: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "255b8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 5 correlated variable names\n",
    "top_5_variable_names = top_5_variables.index.tolist()\n",
    "\n",
    "# Combine with 'equally_weighted_index_lag_1' and 'equally_weighted_volume_lag_1'\n",
    "selected_columns = ['equally_weighted_index_lag_1', 'equally_weighted_volume_lag_1'] + top_5_variable_names + ['Component1LM_lag_1']\n",
    "\n",
    "# Select these columns from X_train and X_test\n",
    "X_train_selected = X_train[selected_columns]\n",
    "X_test_selected = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06cb6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b150c4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 562.341325190349, 'degree': 5}\n",
      "CPU times: total: 24min 52s\n",
      "Wall time: 24min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter ranges\n",
    "C_range = [10**i for i in np.arange(0, 3.25, 0.25)]\n",
    "degree_range = [2, 3, 4, 5]\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'C': C_range, 'degree': degree_range}\n",
    "\n",
    "# Create the SVC model with a polynomial kernel\n",
    "svc = SVC(kernel='poly', class_weight='balanced')\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=10, scoring='f1_weighted')\n",
    "\n",
    "# Fit the GridSearchCV model\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters: ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1797bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = grid_search.best_params_['C']\n",
    "best_d = grid_search.best_params_['degree']\n",
    "\n",
    "# Create a SVC model with the best parameters\n",
    "svc_model_best = SVC(C=best_c, kernel='poly', degree=best_d, decision_function_shape='ovo')\n",
    "\n",
    "# Train the model\n",
    "svc_model_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compute predicted labels for the test set\n",
    "predictions = svc_model_best.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "028a7021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.26      0.32      0.29        37\n",
      "         1.0       0.42      0.52      0.46        69\n",
      "         2.0       0.19      0.08      0.12        48\n",
      "\n",
      "    accuracy                           0.34       154\n",
      "   macro avg       0.29      0.31      0.29       154\n",
      "weighted avg       0.31      0.34      0.31       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[12 22 13]\n",
      " [19 36 31]\n",
      " [ 6 11  4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "# Print out classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions, zero_division=0))\n",
    "\n",
    "# Compute and print out confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68f4e0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.33766233766233766\n",
      "Weighted Macro F1-Score: 0.3129107718568749\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracy_p_lm_comp = accuracy_score(y_test, predictions)\n",
    "print(f\"Average Accuracy: {accuracy_p_lm_comp}\")\n",
    "\n",
    "# Get classification report as a dictionary\n",
    "classification_report_dict = classification_report(y_test, predictions, zero_division=0, output_dict=True)\n",
    "\n",
    "# Extract weighted macro F1-score\n",
    "f1_p_lm_comp = classification_report_dict['weighted avg']['f1-score']\n",
    "print(f\"Weighted Macro F1-Score: {f1_p_lm_comp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de8593d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative improvement for accuracy: -0.2562302562302562\n",
      "Relative improvement for F1 score: 0.10373046271027517\n"
     ]
    }
   ],
   "source": [
    "delta_lm_comp = (accuracy_p_lm_comp - accuracy_p) / accuracy_p\n",
    "delta_lm_comp_f1 = (f1_p_lm_comp - f1_p) / f1_p\n",
    "\n",
    "print(f\"Relative improvement for accuracy: {delta_lm_comp}\")\n",
    "print(f\"Relative improvement for F1 score: {delta_lm_comp_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08352c29",
   "metadata": {},
   "source": [
    "## Prices and extended sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f572770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_daily['labels'][1:]\n",
    "columns = ['equally_weighted_index', 'equally_weighted_volume', 'sentiment_extend']\n",
    "X = data_daily[columns].iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7f9b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the split point for 90% of the data\n",
    "split_point = int(len(X) * 0.90)\n",
    "\n",
    "# Split the data without shuffling\n",
    "X_train, X_test = X[:split_point], X[split_point:]\n",
    "y_train, y_test = y[:split_point], y[split_point:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f067ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 3.1622776601683795, 'degree': 2}\n",
      "CPU times: total: 2h 15min 22s\n",
      "Wall time: 2h 15min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter ranges\n",
    "C_range = [10**i for i in np.arange(0, 3.25, 0.25)]\n",
    "degree_range = [2, 3, 4, 5]\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'C': C_range, 'degree': degree_range}\n",
    "\n",
    "# Create the SVC model with a polynomial kernel\n",
    "svc = SVC(kernel='poly', class_weight='balanced')\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=10, scoring='f1_weighted')\n",
    "\n",
    "# Fit the GridSearchCV model\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters: ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "772e0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = grid_search.best_params_['C']\n",
    "best_d = grid_search.best_params_['degree']\n",
    "\n",
    "# Create a SVC model with the best parameters\n",
    "svc_model_best = SVC(C=best_c, kernel='poly', degree=best_d, decision_function_shape='ovo')\n",
    "\n",
    "# Train the model\n",
    "svc_model_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compute predicted labels for the test set\n",
    "predictions = svc_model_best.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd576f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        40\n",
      "           1       0.45      1.00      0.62        74\n",
      "           2       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.45       163\n",
      "   macro avg       0.15      0.33      0.21       163\n",
      "weighted avg       0.21      0.45      0.28       163\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0]\n",
      " [40 74 49]\n",
      " [ 0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "# Print out classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions, zero_division=0))\n",
    "\n",
    "# Compute and print out confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48df6e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.4539877300613497\n",
      "Weighted Macro F1-Score: 0.28350288628303694\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracy_p_extend = accuracy_score(y_test, predictions)\n",
    "print(f\"Average Accuracy: {accuracy_p_extend}\")\n",
    "\n",
    "# Get classification report as a dictionary\n",
    "classification_report_dict = classification_report(y_test, predictions, zero_division=0, output_dict=True)\n",
    "\n",
    "# Extract weighted macro F1-score\n",
    "f1_p_extend = classification_report_dict['weighted avg']['f1-score']\n",
    "print(f\"Weighted Macro F1-Score: {f1_p_extend}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1ef558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative improvement for accuracy: 0.0\n",
      "Relative improvement for F1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "delta_extend = (accuracy_p_extend - accuracy_p) / accuracy_p\n",
    "delta_extend_f1 = (f1_p_extend - f1_p) / f1_p\n",
    "\n",
    "print(f\"Relative improvement for accuracy: {delta_extend}\")\n",
    "print(f\"Relative improvement for F1 score: {delta_extend_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eb1586",
   "metadata": {},
   "source": [
    "## Prices and components based on topics*extended sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5acbd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test first\n",
    "mask = (data_daily['date'] <= '2021-11-12')\n",
    "train_data = data_daily.loc[mask]\n",
    "mask = (data_daily['date'] >= '2021-11-12')\n",
    "test_data = data_daily.loc[mask]\n",
    "\n",
    "# Add lags to 'equally_weighted_index', 'equally_weighted_volume' and 'Componentiextend' columns in train set\n",
    "train_data = add_lags(train_data, 'equally_weighted_index', 1)\n",
    "train_data = add_lags(train_data, 'equally_weighted_volume', 1)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    train_data = add_lags(train_data, f'Component{i}extend', 10)\n",
    "\n",
    "# Select the required columns\n",
    "required_columns = ['equally_weighted_index_lag_1', 'equally_weighted_volume_lag_1'] + [f'Component{i}extend_lag_{j}' for i in range(1, 11) for j in range(1, 11)]\n",
    "X = train_data[required_columns]\n",
    "y = train_data['labels'].shift(-10)\n",
    "X_train = X.dropna().reset_index(drop=True)\n",
    "y_train = y.dropna().reset_index(drop=True).iloc[:len(X_train)]\n",
    "\n",
    "# Add lags to 'equally_weighted_index', 'equally_weighted_volume' and 'Componentiextend' columns in test set\n",
    "test_data = add_lags(test_data, 'equally_weighted_index', 1)\n",
    "test_data = add_lags(test_data, 'equally_weighted_volume', 1)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    test_data = add_lags(test_data, f'Component{i}extend', 10)\n",
    "\n",
    "# Select the required columns\n",
    "required_columns = ['equally_weighted_index_lag_1', 'equally_weighted_volume_lag_1'] + [f'Component{i}extend_lag_{j}' for i in range(1, 11) for j in range(1, 11)]\n",
    "X = test_data[required_columns]\n",
    "y = test_data['labels'].shift(-10)\n",
    "X_test = X.dropna().reset_index(drop=True)\n",
    "y_test = y.dropna().reset_index(drop=True).iloc[:len(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16e3497d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component6extend_lag_1: 0.06625118490229949\n",
      "Component6extend_lag_2: 0.05931828806761272\n",
      "Component9extend_lag_10: 0.0587815940867539\n",
      "Component4extend_lag_5: 0.041587725346739095\n",
      "Component7extend_lag_7: 0.038547576458769536\n"
     ]
    }
   ],
   "source": [
    "# Drop the specified columns\n",
    "X_train_dropped = X_train.drop(['equally_weighted_index_lag_1', 'equally_weighted_volume_lag_1'], axis=1)\n",
    "\n",
    "# Calculate correlations of all remaining variables with `train_data['log_ret'].iloc[10:]`\n",
    "correlations = X_train_dropped.corrwith(train_data['log_ret'].iloc[10:])\n",
    "\n",
    "# Sort correlations in descending order\n",
    "sorted_correlations = correlations.sort_values(ascending=False)\n",
    "\n",
    "# Select top 5\n",
    "top_5_variables = sorted_correlations[:5]\n",
    "\n",
    "# Print top 5 variables along with their correlation coefficients\n",
    "for variable, correlation in top_5_variables.items():\n",
    "    print(f\"{variable}: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7edc36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 5 correlated variable names\n",
    "top_5_variable_names = top_5_variables.index.tolist()\n",
    "\n",
    "# Combine with 'equally_weighted_index_lag_1' and 'equally_weighted_volume_lag_1'\n",
    "selected_columns = ['equally_weighted_index_lag_1', 'equally_weighted_volume_lag_1'] + top_5_variable_names + ['Component1extend_lag_1']\n",
    "\n",
    "# Select these columns from X_train and X_test\n",
    "X_train_selected = X_train[selected_columns]\n",
    "X_test_selected = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13f91e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "017e0b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 562.341325190349, 'degree': 5}\n",
      "CPU times: total: 23min 7s\n",
      "Wall time: 23min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter ranges\n",
    "C_range = [10**i for i in np.arange(0, 3.25, 0.25)]\n",
    "degree_range = [2, 3, 4, 5]\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'C': C_range, 'degree': degree_range}\n",
    "\n",
    "# Create the SVC model with a polynomial kernel\n",
    "svc = SVC(kernel='poly', class_weight='balanced')\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=10, scoring='f1_weighted')\n",
    "\n",
    "# Fit the GridSearchCV model\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best parameters: ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aaecc4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = grid_search.best_params_['C']\n",
    "best_d = grid_search.best_params_['degree']\n",
    "\n",
    "# Create a SVC model with the best parameters\n",
    "svc_model_best = SVC(C=best_c, kernel='poly', degree=best_d, decision_function_shape='ovo')\n",
    "\n",
    "# Train the model\n",
    "svc_model_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compute predicted labels for the test set\n",
    "predictions = svc_model_best.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8c90cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.21      0.16      0.18        37\n",
      "         1.0       0.49      0.67      0.56        69\n",
      "         2.0       0.32      0.21      0.25        48\n",
      "\n",
      "    accuracy                           0.40       154\n",
      "   macro avg       0.34      0.35      0.33       154\n",
      "weighted avg       0.37      0.40      0.38       154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6 13 10]\n",
      " [20 46 28]\n",
      " [11 10 10]]\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions, zero_division=0))\n",
    "\n",
    "# Compute and print out confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7d178f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.4025974025974026\n",
      "Weighted Macro F1-Score: 0.3754802385553478\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracy_p_extend_comp = accuracy_score(y_test, predictions)\n",
    "print(f\"Average Accuracy: {accuracy_p_extend_comp}\")\n",
    "\n",
    "# Get classification report as a dictionary\n",
    "classification_report_dict = classification_report(y_test, predictions, zero_division=0, output_dict=True)\n",
    "\n",
    "# Extract weighted macro F1-score\n",
    "f1_p_extend_comp = classification_report_dict['weighted avg']['f1-score']\n",
    "print(f\"Weighted Macro F1-Score: {f1_p_extend_comp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80381f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative improvement for accuracy: -0.11319761319761312\n",
      "Relative improvement for F1 score: 0.32443180201165456\n"
     ]
    }
   ],
   "source": [
    "delta_extend_comp = (accuracy_p_extend_comp - accuracy_p) / accuracy_p\n",
    "delta_extend_comp_f1 = (f1_p_extend_comp - f1_p) / f1_p\n",
    "\n",
    "print(f\"Relative improvement for accuracy: {delta_extend_comp}\")\n",
    "print(f\"Relative improvement for F1 score: {delta_extend_comp_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65e4cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary where the keys are the metric names and the values are the metric values\n",
    "metrics_dict = {\n",
    "    'accuracy_p': accuracy_p,\n",
    "    'f1_p': f1_p,\n",
    "    'accuracy_p_lm': accuracy_p_lm,\n",
    "    'f1_p_lm': f1_p_lm,\n",
    "    'accuracy_p_lm_comp': accuracy_p_lm_comp,\n",
    "    'f1_p_lm_comp': f1_p_lm_comp,\n",
    "    'accuracy_p_extend': accuracy_p_extend,\n",
    "    'f1_p_extend': f1_p_extend,\n",
    "    'accuracy_p_extend_comp': accuracy_p_extend_comp,\n",
    "    'f1_p_extend_comp': f1_p_extend_comp\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_dict, index=[0])\n",
    "\n",
    "# Save the DataFrame to a csv file\n",
    "metrics_df.to_csv('metrics_final_experiment_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f002bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary where the keys are the delta names and the values are the delta values\n",
    "deltas_dict = {\n",
    "    'delta_lm': delta_lm,\n",
    "    'delta_lm_f1': delta_lm_f1,\n",
    "    'delta_lm_comp': delta_lm_comp,\n",
    "    'delta_lm_comp_f1': delta_lm_comp_f1,\n",
    "    'delta_extend': delta_extend,\n",
    "    'delta_extend_f1': delta_extend_f1,\n",
    "    'delta_extend_comp': delta_extend_comp,\n",
    "    'delta_extend_comp_f1': delta_extend_comp_f1\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "deltas_df = pd.DataFrame(deltas_dict, index=[0])\n",
    "\n",
    "# Save the DataFrame to a csv file\n",
    "deltas_df.to_csv('deltas_final_experiment_4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FishText",
   "language": "python",
   "name": "fishtext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
