{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1fb3120",
   "metadata": {},
   "source": [
    "In this notebook, we create five datasets for VAR analysis, each combining various elements such as SPI logarithmic returns, sentiment scores, estimated topics, and extracted components:\n",
    "\n",
    "    1. The first dataset includes SPI logarithmic returns, Loughran-McDonald (LM) sentiment scores, and estimated topics.\n",
    "    2. The second dataset extends the first by adding components derived from topics and topics multiplied with LM sentiment.\n",
    "    3. The third dataset combines SPI logarithmic returns with extended sentiment scores and estimated topics.\n",
    "    4. The fourth dataset, similar to the third, consists of SPI logarithmic returns, extended sentiment scores, and estimated topics. The distinction lies in its focus: this dataset is constructed exclusively from articles mentioning either the index firms or their competitors.\n",
    "    5. The fifth dataset is a combination of SPI logarithmic returns, extended sentiment scores, estimated topics, and components based on topics multiplied with extended sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2342673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd4a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.realpath(__name__) # path\n",
    "drt = os.path.dirname(path)       # directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb3450",
   "metadata": {},
   "source": [
    "## The first dataset: returns, LM sentiment, topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e65ec",
   "metadata": {},
   "source": [
    "First, we merge the returns data with the estimated daily topics and LM sentiment. The combined dataset is then saved into a CSV file named `daily_topics_LM.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dadaa8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths\n",
    "# returns\n",
    "daily_ret_import = drt + '/daily/daily_common.csv' \n",
    "# topics\n",
    "daily_topics_import = drt.replace('\\\\finance data', '') + '\\\\analysis\\\\analysis_topics' + '/daily_topics.csv'\n",
    "# LM sentiment\n",
    "daily_sentiment_path = drt.replace('\\\\finance data', '') + '\\\\analysis' + '/sentiment_daily_LM.xlsx'\n",
    "daily_sentiment = pd.read_excel(daily_sentiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea2be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import daily SPI data:\n",
    "daily_returns = pd.read_csv(daily_ret_import)\n",
    "# Topics data:\n",
    "daily_topics = pd.read_csv(daily_topics_import)\n",
    "# Rename the 'dates_day' column to 'date':\n",
    "daily_topics.rename(columns = {'dates_day':'date'}, inplace = True)\n",
    "daily_sentiment.rename(columns = {'dates_day':'date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cb7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge together:\n",
    "daily_topics = pd.merge(daily_returns, daily_topics, on=['date'], how='outer')\n",
    "daily_topics = pd.merge(daily_topics, daily_sentiment, on=['date'], how='outer')\n",
    "# Delete columns 'common', 'react_label', 'day', 'month', and 'year':\n",
    "daily_topics = daily_topics.drop([\"common\", \"react_label\", \"day\", \"month\", 'year'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f1d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_topics = daily_topics.loc[7:,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f30ce2",
   "metadata": {},
   "source": [
    "In cases where there are log returns data but no corresponding news articles on a particular trading day, we fill the missing topic data by carrying forward the topics from the previous day. This approach is based on the assumption that the topics discussed on the last available trading day continue to influence the market until new information becomes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a504b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_topics = daily_topics.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc91129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DF:\n",
    "daily_topics.to_csv('daily/daily_topics_LM.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ea36d",
   "metadata": {},
   "source": [
    "## The second dataset: returns, LM sentiment, topics, components based on topics, components based on topics multiplied with LM sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c731225",
   "metadata": {},
   "source": [
    "Now we add components based on topics and topics multiplied with LM sentiment. The resulting dataset is saved into a CSV file named `daily_topics_LM_components.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14dc6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import daily SPI data:\n",
    "daily_returns = pd.read_csv(daily_ret_import)\n",
    "# Topics data:\n",
    "daily_topics = pd.read_csv(daily_topics_import)\n",
    "# LM sentiment:\n",
    "daily_sentiment = pd.read_excel(daily_sentiment_path)\n",
    "# Rename the 'dates_day' column to 'date':\n",
    "daily_topics.rename(columns = {'dates_day':'date'}, inplace = True)\n",
    "daily_sentiment.rename(columns = {'dates_day':'date'}, inplace = True)\n",
    "\n",
    "# Set the paths\n",
    "# components based on topics\n",
    "daily_components_import = drt.replace('\\\\finance data', '') + '\\\\analysis\\\\VAR' + '/components.csv'\n",
    "# components based on topics multiplied with sentiment\n",
    "daily_components_sent_import = drt.replace('\\\\finance data', '') + '\\\\analysis\\\\VAR' + '/components_sent.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73120c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components\n",
    "daily_components = pd.read_csv(daily_components_import)\n",
    "daily_components_sent = pd.read_csv(daily_components_sent_import)\n",
    "\n",
    "# Convert date format in 'daily_components' to 'YYYY-MM-DD'\n",
    "daily_components['date'] = pd.to_datetime(daily_components['date'], dayfirst=True).dt.strftime('%Y-%m-%d')\n",
    "# Convert date format in 'daily_components_sent' to 'YYYY-MM-DD'\n",
    "daily_components_sent['date'] = pd.to_datetime(daily_components_sent['date'], dayfirst=True).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "893ec78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge together:\n",
    "daily_topics = pd.merge(daily_returns, daily_topics, on=['date'], how='outer')\n",
    "daily_topics = pd.merge(daily_topics, daily_sentiment, on=['date'], how='outer')\n",
    "daily_topics = pd.merge(daily_topics, daily_components, on=['date'], how='outer')\n",
    "daily_topics = pd.merge(daily_topics, daily_components_sent, on=['date'], how='outer')\n",
    "# Delete columns 'common', 'react_label', 'day', 'month', and 'year':\n",
    "daily_topics = daily_topics.drop([\"common\", \"react_label\", \"day\", \"month\", 'year'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21699999",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_topics = daily_topics.loc[7:,:].reset_index(drop = True)\n",
    "daily_topics = daily_topics.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c54275b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DF:\n",
    "daily_topics.to_csv('daily/daily_topics_LM_components.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699bbbce",
   "metadata": {},
   "source": [
    "## The third dataset: returns, extended sentiment, and topics (all articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f41fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths \n",
    "# extended sentiment:\n",
    "daily_sentiment_path = drt.replace('\\\\finance data', '') + '\\\\analysis' + '/sentiment_daily_extend_comp_rev.xlsx'\n",
    "daily_sentiment = pd.read_excel(daily_sentiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a7d63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import daily SPI data:\n",
    "daily_returns = pd.read_csv(daily_ret_import)\n",
    "# Topics data:\n",
    "daily_topics = pd.read_csv(daily_topics_import)\n",
    "# Rename the 'dates_day' column to 'date':\n",
    "daily_topics.rename(columns = {'dates_day':'date'}, inplace = True)\n",
    "daily_sentiment.rename(columns = {'dates_day':'date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d1dbf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge together:\n",
    "daily_topics = pd.merge(daily_returns, daily_topics, on=['date'], how='outer')\n",
    "daily_topics = pd.merge(daily_topics, daily_sentiment, on=['date'], how='outer')\n",
    "# Delete columns 'common', 'react_label', 'day', 'month', and 'year':\n",
    "daily_topics = daily_topics.drop([\"common\", \"react_label\", \"day\", \"month\", 'year'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83115442",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_topics = daily_topics.loc[7:,:].reset_index(drop = True)\n",
    "daily_topics = daily_topics.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdeba6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DF:\n",
    "daily_topics.to_csv('daily/daily_topics_extend_comp_rev.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8cf0c",
   "metadata": {},
   "source": [
    "## The fourth dataset: returns, extended sentiment, and topics (our firms and competitors, not all articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e24e0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths\n",
    "# Topics: our firms and competitors\n",
    "daily_topics_import = drt.replace('\\\\finance data', '') + '\\\\analysis\\\\analysis_topics' + '/daily_topics_our_comp.csv'\n",
    "# Extended sentiment: our firms and competitors\n",
    "daily_sentiment_path = drt.replace('\\\\finance data', '') + '\\\\analysis' + '/sentiment_daily_extend_our_comp.xlsx'\n",
    "daily_sentiment = pd.read_excel(daily_sentiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "912cba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import daily SPI data:\n",
    "daily_returns = pd.read_csv(daily_ret_import)\n",
    "# Topics data:\n",
    "daily_topics = pd.read_csv(daily_topics_import)\n",
    "# Rename the 'dates_day' column to 'date':\n",
    "daily_topics.rename(columns = {'dates_day':'date'}, inplace = True)\n",
    "daily_sentiment.rename(columns = {'dates_day':'date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57e675fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge together:\n",
    "daily_topics = pd.merge(daily_returns, daily_topics, on=['date'], how='left')\n",
    "daily_topics = pd.merge(daily_topics, daily_sentiment, on=['date'], how='outer')\n",
    "daily_topics = daily_topics.drop([\"common\", \"react_label\", \"day\", \"month\", 'year'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f37e3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_topics = daily_topics.loc[13:,:].reset_index(drop = True)\n",
    "daily_topics = daily_topics.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60d26016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DF:\n",
    "daily_topics.to_csv('daily/daily_topics_extend_our_comp.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d1b35",
   "metadata": {},
   "source": [
    "## The fifth dataset: returns, extended sentiment, topics, and components based on topics multiplied with extended sentiment (all articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "055574bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths\n",
    "daily_topics_import = drt.replace('\\\\finance data', '') + '\\\\analysis\\\\analysis_topics' + '/daily_topics.csv'\n",
    "# Extended sentiment\n",
    "daily_sentiment_path = drt.replace('\\\\finance data', '') + '\\\\analysis' + '/sentiment_daily_extend_comp_rev.xlsx'\n",
    "daily_sentiment = pd.read_excel(daily_sentiment_path)\n",
    "# Components based on topics multiplied with extended sentiment\n",
    "daily_components_sent_extend_import = drt.replace('\\\\finance data', '') + '\\\\analysis\\\\VAR' + '/components_sent_extend.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f12cb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import daily SPI data:\n",
    "daily_returns = pd.read_csv(daily_ret_import)\n",
    "# Topics data:\n",
    "daily_topics = pd.read_csv(daily_topics_import)\n",
    "daily_topics.rename(columns = {'dates_day':'date'}, inplace = True)\n",
    "daily_sentiment.rename(columns = {'dates_day':'date'}, inplace = True)\n",
    "## Components\n",
    "daily_components_sent_extend = pd.read_csv(daily_components_sent_extend_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a47c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge together:\n",
    "daily_topics = pd.merge(daily_returns, daily_topics, on=['date'], how='outer')\n",
    "daily_topics = pd.merge(daily_topics, daily_sentiment, on=['date'], how='outer')\n",
    "daily_topics = pd.merge(daily_topics, daily_components_sent_extend, on=['date'], how='outer')\n",
    "daily_topics = daily_topics.drop([\"common\", \"react_label\", \"day\", \"month\", 'year'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff2ac2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_topics = daily_topics.loc[7:,:].reset_index(drop = True)\n",
    "daily_topics = daily_topics.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6902c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DF:\n",
    "daily_topics.to_csv('daily/daily_topics_extend_comp_rev_components.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FishText",
   "language": "python",
   "name": "fishtext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
